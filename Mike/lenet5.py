# -*- coding: utf-8 -*-
"""LeNet5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivd7KdCCEjlYw8uvhozjsLiWDaGLJbSJ
"""

import math
import copy
import tensorflow as tf
#import cv2 as cv
#from google.colab.patches import cv2_imshow
import numpy as np
import matplotlib
from matplotlib import pyplot as plt
from keras import models
import keras.layers as layers
#from sklearn.metrics import classification_report, confusion_matrix
#import seaborn as sns
from keras.callbacks import  EarlyStopping
from keras.callbacks import Callback
#from tensorflow.keras.applications.vgg16 import preprocess_input
#from tensorflow.keras.applications.vgg16 import decode_predictions
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.data import Dataset
#from keras import  backend as K
#import tensorflow_datasets as tfds
from src.loss_log_callback import LossLogCallback
from src.utils import printSomeDatasetSamples

# Controls
plt.rcParams['font.size'] = 6


def load_dataset():
  # load dataset
  (x_train, y_train), (x_test, y_test) = (None, None), (None, None)
  #for i in range(len(x_test)):
  #  subDirectoryName = 'digit_' + str(y_test[i])
  #  x = 255 - x_test[i].reshape(28, 28, 1)
  #  tf.keras.preprocessing.image.save_img('test_mnist/%s/sample_%d.jpg'%(subDirectoryName, i), x)
  artificial_data = image_dataset_from_directory('outputs/polygons/images', batch_size=1024, image_size=(100, 100), color_mode='grayscale')
  x_train = []
  y_train = []
  for x_batch, y_batch in artificial_data:
    for i in range(len(x_batch)):
      x = x_batch[i]
      y = y_batch[i]
      x_train.append(x)
      y_train.append(y)
  x_train = np.array(x_train)
  y_train = np.array(y_train)

  
  test_data = image_dataset_from_directory('NeatSet', batch_size=1024, image_size=(100, 100), color_mode='grayscale')
  x_test = []
  y_test = []
  for x_batch, y_batch in test_data:
    for i in range(len(x_batch)):
      x = x_batch[i]
      y = y_batch[i]
      x_test.append(x)
      y_test.append(y)
  x_test = np.array(x_test)
  y_test = np.array(y_test)

  # reshape dataset to have a single channel
  x_train = x_train.reshape((x_train.shape[0], 100, 100, 1))
  x_test = x_test.reshape((x_test.shape[0], 100, 100, 1))
  # one hot encode target values
  y_train = tf.keras.utils.to_categorical(y_train)
  y_test = tf.keras.utils.to_categorical(y_test)

  return x_train, y_train, x_test, y_test

x_train, y_train, x_test, y_test = load_dataset()

# scale pixels
def prep_pixels(train, test):
	# normalize to range 0-1
  train_norm = train.astype('float32') / 255.0
  test_norm = test.astype('float32') / 255.0
	# return normalized images

  return train_norm, test_norm

x_train, x_test = prep_pixels(x_train,x_test)

# Pad images with 0s
x_train = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')
x_test = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')

# Save some sample images from the dataset
printSomeDatasetSamples(x_train, y_train, 'output/sample_images.jpg')

def create_model():
  model = tf.keras.Sequential()
  model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu'))
  model.add(layers.AveragePooling2D())

  model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
  model.add(layers.AveragePooling2D())

  model.add(layers.Flatten())

  model.add(layers.Dense(units=120, activation='relu'))

  model.add(layers.Dense(units=84, activation='relu'))

  model.add(layers.Dense(units=6, activation = 'softmax'))
  return model

model = create_model()

model.build(input_shape=(None,104,104,1))

model.summary()

model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(0.001), metrics=['accuracy'])

#es = EarlyStopping(monitor='loss', mode = "min", patience=3)
es = LossLogCallback(x_test, y_test, 'output/artificial_loss_log.txt', 'output/artificial_loss_plot', 'output/artificial_accuracy_plot', patience=15)


model.fit(x_train,
          y_train,
          epochs = 100,
          validation_data=(x_test,y_test),
          callbacks = [es],
          verbose=0)

#model.save_weights("drive/MyDrive/LeNet 5 trained by MNIST/")













# I'll clean this up later
def getIndexOfTopFew(num_list, num_to_get):
  top_few_indices = []
  temp_list = copy.copy(num_list)
  while len(top_few_indices) < num_to_get:
    next_max_value = max(temp_list)
    next_top_index = num_list.index(next_max_value)
    while next_top_index in top_few_indices:
      next_top_index = next_top_index + 1 + num_list[next_top_index + 1:len(num_list)].index(next_max_value)
    del temp_list[temp_list.index(next_max_value)]
    top_few_indices.append(next_top_index)
  return top_few_indices

def getIndexOfBotomFew(num_list, num_to_get):
  bottom_few_indices = []
  temp_list = copy.copy(num_list)
  while len(bottom_few_indices) < num_to_get:
    next_min_value = min(temp_list)
    next_bottom_index = num_list.index(next_min_value)
    while next_bottom_index in bottom_few_indices:
      next_bottom_index = next_bottom_index + 1 + num_list[next_bottom_index + 1:len(num_list)].index(next_min_value)
    del temp_list[temp_list.index(next_min_value)]
    bottom_few_indices.append(next_bottom_index)
  return bottom_few_indices

# Sort the test dataset by class
x_test_by_class = [[] for i in range(6)]
y_test_by_class = [[] for i in range(6)]
for i in range(len(x_test)):
  class_index = y_test[i].tolist().index(1.0)
  x_test_by_class[class_index].append(x_test[i])
  y_test_by_class[class_index].append(y_test[i])
for i in range(6):
  x_test_by_class[i] = np.array(x_test_by_class[i])
  y_test_by_class[i] = np.array(y_test_by_class[i])

# Print some good and some bad examples
EXAMPLE_COUNT = 5
for class_index in range(6):
  # Break down the test predictions for this class
  predictions = model.predict(x_test_by_class[class_index])
  correct_probs = []
  greatest_wrong_classes = []
  greatest_wrong_probs = []
  greatest_dif_from_correct_probs = []
  for prediction_index in range(len(predictions)):
    prediction = predictions[prediction_index]
    correct_prob = prediction[class_index]
    greatest_wrong_class = None
    greatest_wrong_prob = 0.0
    greatest_dif_from_correct_prob = 1.0
    for output_index in range(len(prediction)):
      if output_index != class_index and prediction[output_index] > greatest_wrong_prob:
        greatest_wrong_class = output_index
        greatest_wrong_prob = prediction[output_index]
        greatest_dif_from_correct_prob = correct_prob - prediction[output_index]
    correct_probs.append(correct_prob)
    greatest_wrong_classes.append(greatest_wrong_class)
    greatest_wrong_probs.append(greatest_wrong_prob)
    greatest_dif_from_correct_probs.append(greatest_dif_from_correct_prob)
  
  # Get accuracy
  (testLoss, testAccuracy) = model.evaluate(x_test_by_class[class_index], y_test_by_class[class_index], verbose=0)

  # Now export an image
  fig, subplots = plt.subplots(2, EXAMPLE_COUNT)
  fig.suptitle('Total Accuracy: %.2f%s'%(testAccuracy * 100.0, '%'), fontsize=16)
  best_few_indices = getIndexOfTopFew(greatest_dif_from_correct_probs, EXAMPLE_COUNT)
  for example_index in range(len(best_few_indices)):
    some_best_index = best_few_indices[example_index]
    some_best_image = x_test_by_class[class_index][some_best_index]
    correct_prob = correct_probs[some_best_index]
    greatest_wrong_class = greatest_wrong_classes[some_best_index]
    greatest_wrong_prob = greatest_wrong_probs[some_best_index]
    greatest_dif_from_correct_prob = greatest_dif_from_correct_probs[some_best_index]
    subplots[0, example_index].axis('off')
    subplots[0, example_index].title.set_text('%d: %.2f, %d: %.2f'%(class_index, correct_prob, greatest_wrong_class, greatest_wrong_prob))
    subplots[0, example_index].imshow(some_best_image, cmap=plt.get_cmap('gray'))
  worst_few_indices = getIndexOfBotomFew(greatest_dif_from_correct_probs, EXAMPLE_COUNT)
  for example_index in range(len(worst_few_indices)):
    some_worst_index = worst_few_indices[example_index]
    some_worst_image = x_test_by_class[class_index][some_worst_index]
    correct_prob = correct_probs[some_worst_index]
    greatest_wrong_class = greatest_wrong_classes[some_worst_index]
    greatest_wrong_prob = greatest_wrong_probs[some_worst_index]
    greatest_dif_from_correct_prob = greatest_dif_from_correct_probs[some_worst_index]
    subplots[1, example_index].axis('off')
    subplots[1, example_index].title.set_text('%d: %.2f, %d: %.2f'%(class_index, correct_prob, greatest_wrong_class, greatest_wrong_prob))
    subplots[1, example_index].imshow(some_worst_image, cmap=plt.get_cmap('gray'))
  plt.savefig('output/digit_%d_sample_images.jpg'%(class_index))
  plt.close()
    