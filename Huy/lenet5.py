# -*- coding: utf-8 -*-
"""LeNet5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivd7KdCCEjlYw8uvhozjsLiWDaGLJbSJ
"""

import tensorflow as tf
import cv2 as cv
from google.colab.patches import cv2_imshow
import numpy as np
from matplotlib import pyplot as plt
from keras import models
import keras.layers as layers
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from keras.callbacks import  EarlyStopping
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.applications.vgg16 import decode_predictions
from keras import  backend as K
import tensorflow_datasets as tfds

def load_dataset():
  # load dataset
  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
 # reshape dataset to have a single channel
  x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))
  x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))
  # one hot encode target values
  y_train = tf.keras.utils.to_categorical(y_train)
  y_test = tf.keras.utils.to_categorical(y_test)

  return x_train, y_train, x_test, y_test

x_train, y_train, x_test, y_test = load_dataset()

# scale pixels
def prep_pixels(train, test):
	# normalize to range 0-1
  train_norm = train.astype('float32') / 255.0
  test_norm = test.astype('float32') / 255.0
	# return normalized images

  return train_norm, test_norm

x_train, x_test = prep_pixels(x_train,x_test)

# Pad images with 0s
x_train = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')
x_test = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')

print(x_train.shape)

def create_model():
  model = tf.keras.Sequential()
  model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu'))
  model.add(layers.AveragePooling2D())

  model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
  model.add(layers.AveragePooling2D())

  model.add(layers.Flatten())

  model.add(layers.Dense(units=120, activation='relu'))

  model.add(layers.Dense(units=84, activation='relu'))

  model.add(layers.Dense(units=10, activation = 'softmax'))
  return model

model = create_model()

model.build(input_shape=(None,32,32,1))

model.summary()

model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(0.001), metrics=['accuracy'])

es = EarlyStopping(monitor='loss', mode = "min", patience=3)
model.fit(x_train,
          y_train,
          epochs = 100,
          validation_data=(x_test,y_test),
          callbacks = [es])

model.save_weights("drive/MyDrive/LeNet 5 trained by MNIST/")